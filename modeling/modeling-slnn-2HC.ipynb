{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMRI = pd.read_csv('mri.csv')\n",
    "dataCSF = pd.read_csv('csf.csv')\n",
    "dataUDS = pd.read_csv('uds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NACCID  NACCICV  NACCBRNV  NACCWMVL  FRONTGRY  FRONTWHT  FRONTCSF  \\\n",
      "0  NACC914950  1535.13   1081.63    504.80       NaN       NaN       NaN   \n",
      "1  NACC388999  1314.57   1001.09    437.70       NaN       NaN       NaN   \n",
      "2  NACC550785  1571.92   1210.39    516.57       NaN       NaN       NaN   \n",
      "3  NACC321645  1417.97   1043.73    431.46       NaN       NaN       NaN   \n",
      "4  NACC129206  1553.60   1086.93    425.40       NaN       NaN       NaN   \n",
      "\n",
      "   OCCIPGRY  OCCIPWHT  OCCIPCSF  ...  RSUPTEMM  RSUPMAR  RSUPMARM  RTRTEM  \\\n",
      "0       NaN       NaN       NaN  ...      2.02     7.24      1.89    0.72   \n",
      "1       NaN       NaN       NaN  ...      2.17     8.92      2.09    0.63   \n",
      "2       NaN       NaN       NaN  ...      2.01    10.37      1.89    0.75   \n",
      "3       NaN       NaN       NaN  ...      2.06     8.38      1.97    0.98   \n",
      "4       NaN       NaN       NaN  ...      2.32    10.38      2.02    1.80   \n",
      "\n",
      "   RTRTEMM  NACCVNUM    datetime  datetime_UDS  timediff  within-a-year  \n",
      "0     1.21        11  2017-03-02    2006-10-31      3775          False  \n",
      "1     1.61        11  2016-06-24    2006-02-21      3776          False  \n",
      "2     1.90        10  2015-06-02    2006-03-28      3353          False  \n",
      "3     1.58         9  2015-12-03    2006-01-03      3621          False  \n",
      "4     2.28        10  2015-12-09    2006-04-18      3522          False  \n",
      "\n",
      "[5 rows x 173 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataMRI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NACCID  CSFABETA  CSFABMD  CSFTTAU  CSFTTMD  CSFPTAU  CSFPTMD\n",
      "0  NACC000441    220.32        2   219.18      2.0    103.1      2.0\n",
      "1  NACC001235    247.77        1   785.89      1.0    146.7      1.0\n",
      "2  NACC001634    177.00        2   135.00      2.0     95.0      2.0\n",
      "3  NACC001689    266.00        8   313.00      8.0     48.0      8.0\n",
      "4  NACC002539    626.00        8   999.00      8.0    149.0      8.0\n"
     ]
    }
   ],
   "source": [
    "print(dataCSF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NACCID  NACCADC  NACCAGE  NACCVNUM  EDUC  SEX  NACCAPOE  NACCUDSD  \\\n",
      "0  NACC020208      186       69         1  16.0    1       NaN         3   \n",
      "1  NACC107305      186       74         1  18.0    2       NaN         1   \n",
      "2  NACC151065      186       86         1  14.0    2       NaN         3   \n",
      "3  NACC187327      186       68         1  14.0    2       NaN         1   \n",
      "4  NACC188799      186       78         1  14.0    2       NaN         3   \n",
      "\n",
      "   NACCALZP  MEMORY  ...  BOSTON  MINTTOTS  CRAFTDRE  DIGFORCT  DIGFORSL  \\\n",
      "0         1     1.0  ...    27.0      29.0       1.0       8.0       6.0   \n",
      "1         8     0.0  ...    30.0      32.0      15.0       7.0       6.0   \n",
      "2         7     0.0  ...    26.0      28.0      16.0       3.0       4.0   \n",
      "3         8     0.5  ...    27.0      29.0      17.0      10.0       7.0   \n",
      "4         7     0.5  ...    21.0      24.0       0.0       7.0       6.0   \n",
      "\n",
      "   DIGBACCT  DIGBACLS    datetime  NACCAD3    NACCAD5  \n",
      "0       7.0       5.0  2020-06-09   MCI-AD     MCI-AD  \n",
      "1       6.0       5.0  2021-12-01  Healthy    Healthy  \n",
      "2       2.0       2.0  2021-12-21      NaN  MCI-NonAD  \n",
      "3       9.0       6.0  2021-09-14  Healthy    Healthy  \n",
      "4       7.0       5.0  2022-02-07      NaN  MCI-NonAD  \n",
      "\n",
      "[5 rows x 96 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataUDS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(pd.merge(dataUDS, dataCSF, on='NACCID', how='outer'), dataMRI, on='NACCID', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       NACCID  NACCADC  NACCAGE  NACCVNUM_x  EDUC  SEX  NACCAPOE  NACCUDSD  \\\n",
      "0  NACC000011     1416       62           1  16.0    2       1.0         3   \n",
      "1  NACC000034     9661       79           1  15.0    2       4.0         3   \n",
      "2  NACC000067     2096       60           1  18.0    1       1.0         3   \n",
      "3  NACC000073     5452       44           1  18.0    2       NaN         1   \n",
      "4  NACC000095     2578       87           1  16.0    1       2.0         4   \n",
      "\n",
      "   NACCALZP  MEMORY  ...  RSUPTEMM  RSUPMAR  RSUPMARM  RTRTEM  RTRTEMM  \\\n",
      "0         7     0.5  ...       NaN      NaN       NaN     NaN      NaN   \n",
      "1         1     0.5  ...       NaN      NaN       NaN     NaN      NaN   \n",
      "2         7     0.0  ...       NaN      NaN       NaN     NaN      NaN   \n",
      "3         8     0.0  ...       NaN      NaN       NaN     NaN      NaN   \n",
      "4         1     1.0  ...       NaN      NaN       NaN     NaN      NaN   \n",
      "\n",
      "   NACCVNUM_y  datetime_y  datetime_UDS  timediff  within-a-year  \n",
      "0         NaN         NaN           NaN       NaN            NaN  \n",
      "1         NaN         NaN           NaN       NaN            NaN  \n",
      "2         NaN         NaN           NaN       NaN            NaN  \n",
      "3         NaN         NaN           NaN       NaN            NaN  \n",
      "4         NaN         NaN           NaN       NaN            NaN  \n",
      "\n",
      "[5 rows x 274 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['NACCID','SEX', 'EDUC', 'NACCAGE', 'VEG', 'ANIMALS', 'TRAILA', 'TRAILB', 'CRAFTDRE', 'MINTTOTS', 'DIGBACCT', 'MEMPROB', 'DROPACT', 'WRTHLESS', 'BETTER', 'BORED', 'HELPLESS', 'TAXES', 'BILLS', 'REMDATES', 'TRAVEL', 'NACCUDSD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(axis=0, how='any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['SEX', 'EDUC', 'NACCAGE', 'VEG', 'ANIMALS', 'TRAILA', 'TRAILB', 'CRAFTDRE', 'MINTTOTS', 'DIGBACCT', 'MEMPROB', 'DROPACT', 'WRTHLESS', 'BETTER', 'BORED', 'HELPLESS', 'TAXES', 'BILLS', 'REMDATES', 'TRAVEL', 'NACCUDSD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_value(x):\n",
    "    if x in [1, 2]:\n",
    "        return 0\n",
    "    elif x in [3, 4]:\n",
    "        return 1\n",
    "    else:\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['NACCUDSD'] = merged_df['NACCUDSD'].apply(transform_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = merged_df.iloc[:, :-1].values\n",
    "y = merged_df.iloc[:, -1].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = to_categorical(y) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scalerFunction = StandardScaler()\n",
    "X_train = scalerFunction.fit_transform(X_train)\n",
    "X_test = scalerFunction.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wesle\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='tanh', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSProp',\n",
    "              loss='binary_crossentropy',  \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.8047 - loss: 0.4610 - val_accuracy: 0.8467 - val_loss: 0.3556\n",
      "Epoch 2/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - accuracy: 0.8491 - loss: 0.3383 - val_accuracy: 0.8459 - val_loss: 0.3516\n",
      "Epoch 3/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.8504 - loss: 0.3410 - val_accuracy: 0.8490 - val_loss: 0.3516\n",
      "Epoch 4/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.8560 - loss: 0.3262 - val_accuracy: 0.8467 - val_loss: 0.3513\n",
      "Epoch 5/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8509 - loss: 0.3285 - val_accuracy: 0.8506 - val_loss: 0.3500\n",
      "Epoch 6/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.8549 - loss: 0.3273 - val_accuracy: 0.8521 - val_loss: 0.3499\n",
      "Epoch 7/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.8542 - loss: 0.3273 - val_accuracy: 0.8529 - val_loss: 0.3504\n",
      "Epoch 8/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8611 - loss: 0.3216 - val_accuracy: 0.8506 - val_loss: 0.3507\n",
      "Epoch 9/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8549 - loss: 0.3289 - val_accuracy: 0.8498 - val_loss: 0.3509\n",
      "Epoch 10/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 0.8553 - loss: 0.3327 - val_accuracy: 0.8514 - val_loss: 0.3497\n",
      "Epoch 11/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.8663 - loss: 0.3133 - val_accuracy: 0.8514 - val_loss: 0.3498\n",
      "Epoch 12/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.8555 - loss: 0.3265 - val_accuracy: 0.8506 - val_loss: 0.3507\n",
      "Epoch 13/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.8530 - loss: 0.3294 - val_accuracy: 0.8514 - val_loss: 0.3507\n",
      "Epoch 14/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.8589 - loss: 0.3185 - val_accuracy: 0.8537 - val_loss: 0.3491\n",
      "Epoch 15/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.8530 - loss: 0.3389 - val_accuracy: 0.8521 - val_loss: 0.3508\n",
      "Epoch 16/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.8599 - loss: 0.3153 - val_accuracy: 0.8475 - val_loss: 0.3515\n",
      "Epoch 17/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.8630 - loss: 0.3138 - val_accuracy: 0.8537 - val_loss: 0.3490\n",
      "Epoch 18/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - accuracy: 0.8599 - loss: 0.3158 - val_accuracy: 0.8529 - val_loss: 0.3493\n",
      "Epoch 19/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - accuracy: 0.8597 - loss: 0.3176 - val_accuracy: 0.8514 - val_loss: 0.3497\n",
      "Epoch 20/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.8612 - loss: 0.3173 - val_accuracy: 0.8514 - val_loss: 0.3531\n",
      "Epoch 21/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.8639 - loss: 0.3224 - val_accuracy: 0.8514 - val_loss: 0.3515\n",
      "Epoch 22/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - accuracy: 0.8676 - loss: 0.3033 - val_accuracy: 0.8529 - val_loss: 0.3492\n",
      "Epoch 23/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.8708 - loss: 0.3092 - val_accuracy: 0.8506 - val_loss: 0.3533\n",
      "Epoch 24/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.8575 - loss: 0.3238 - val_accuracy: 0.8529 - val_loss: 0.3530\n",
      "Epoch 25/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 0.8729 - loss: 0.2982 - val_accuracy: 0.8482 - val_loss: 0.3518\n",
      "Epoch 26/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8649 - loss: 0.3145 - val_accuracy: 0.8506 - val_loss: 0.3534\n",
      "Epoch 27/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.8742 - loss: 0.3043 - val_accuracy: 0.8482 - val_loss: 0.3549\n",
      "Epoch 28/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8672 - loss: 0.3065 - val_accuracy: 0.8506 - val_loss: 0.3522\n",
      "Epoch 29/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.8661 - loss: 0.3117 - val_accuracy: 0.8490 - val_loss: 0.3526\n",
      "Epoch 30/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.8636 - loss: 0.3153 - val_accuracy: 0.8482 - val_loss: 0.3539\n",
      "Epoch 31/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.8695 - loss: 0.3047 - val_accuracy: 0.8482 - val_loss: 0.3509\n",
      "Epoch 32/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.8660 - loss: 0.3088 - val_accuracy: 0.8475 - val_loss: 0.3553\n",
      "Epoch 33/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8648 - loss: 0.2997 - val_accuracy: 0.8467 - val_loss: 0.3541\n",
      "Epoch 34/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - accuracy: 0.8771 - loss: 0.2871 - val_accuracy: 0.8467 - val_loss: 0.3509\n",
      "Epoch 35/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.8658 - loss: 0.3049 - val_accuracy: 0.8490 - val_loss: 0.3550\n",
      "Epoch 36/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - accuracy: 0.8788 - loss: 0.2950 - val_accuracy: 0.8467 - val_loss: 0.3521\n",
      "Epoch 37/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - accuracy: 0.8680 - loss: 0.3070 - val_accuracy: 0.8428 - val_loss: 0.3557\n",
      "Epoch 38/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.8707 - loss: 0.3014 - val_accuracy: 0.8482 - val_loss: 0.3536\n",
      "Epoch 39/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.8763 - loss: 0.2901 - val_accuracy: 0.8436 - val_loss: 0.3546\n",
      "Epoch 40/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.8734 - loss: 0.2954 - val_accuracy: 0.8436 - val_loss: 0.3569\n",
      "Epoch 41/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.8722 - loss: 0.3016 - val_accuracy: 0.8482 - val_loss: 0.3596\n",
      "Epoch 42/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - accuracy: 0.8797 - loss: 0.2860 - val_accuracy: 0.8451 - val_loss: 0.3574\n",
      "Epoch 43/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - accuracy: 0.8757 - loss: 0.2989 - val_accuracy: 0.8475 - val_loss: 0.3602\n",
      "Epoch 44/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - accuracy: 0.8738 - loss: 0.2926 - val_accuracy: 0.8451 - val_loss: 0.3603\n",
      "Epoch 45/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.8764 - loss: 0.2959 - val_accuracy: 0.8482 - val_loss: 0.3578\n",
      "Epoch 46/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.8893 - loss: 0.2714 - val_accuracy: 0.8498 - val_loss: 0.3589\n",
      "Epoch 47/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.8821 - loss: 0.2790 - val_accuracy: 0.8451 - val_loss: 0.3624\n",
      "Epoch 48/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - accuracy: 0.8824 - loss: 0.2922 - val_accuracy: 0.8482 - val_loss: 0.3632\n",
      "Epoch 49/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.8755 - loss: 0.2905 - val_accuracy: 0.8444 - val_loss: 0.3625\n",
      "Epoch 50/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - accuracy: 0.8733 - loss: 0.3006 - val_accuracy: 0.8451 - val_loss: 0.3635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2216dcedb50>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.8307 - loss: 0.3469\n",
      "Test loss: 0.3486357033252716\n",
      "Test accuracy: 0.835616409778595\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - auc: 0.9564 - loss: 0.2674 - val_auc: 0.9196 - val_loss: 0.3627\n",
      "Epoch 2/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - auc: 0.9517 - loss: 0.2823 - val_auc: 0.9205 - val_loss: 0.3622\n",
      "Epoch 3/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - auc: 0.9528 - loss: 0.2791 - val_auc: 0.9198 - val_loss: 0.3616\n",
      "Epoch 4/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - auc: 0.9524 - loss: 0.2810 - val_auc: 0.9192 - val_loss: 0.3655\n",
      "Epoch 5/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - auc: 0.9530 - loss: 0.2786 - val_auc: 0.9191 - val_loss: 0.3666\n",
      "Epoch 6/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - auc: 0.9553 - loss: 0.2715 - val_auc: 0.9189 - val_loss: 0.3661\n",
      "Epoch 7/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - auc: 0.9560 - loss: 0.2694 - val_auc: 0.9185 - val_loss: 0.3652\n",
      "Epoch 8/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - auc: 0.9552 - loss: 0.2724 - val_auc: 0.9188 - val_loss: 0.3703\n",
      "Epoch 9/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - auc: 0.9536 - loss: 0.2762 - val_auc: 0.9189 - val_loss: 0.3660\n",
      "Epoch 10/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9571 - loss: 0.2661 - val_auc: 0.9176 - val_loss: 0.3706\n",
      "Epoch 11/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9559 - loss: 0.2696 - val_auc: 0.9175 - val_loss: 0.3743\n",
      "Epoch 12/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - auc: 0.9559 - loss: 0.2694 - val_auc: 0.9154 - val_loss: 0.3732\n",
      "Epoch 13/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - auc: 0.9573 - loss: 0.2669 - val_auc: 0.9149 - val_loss: 0.3758\n",
      "Epoch 14/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - auc: 0.9533 - loss: 0.2771 - val_auc: 0.9154 - val_loss: 0.3783\n",
      "Epoch 15/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - auc: 0.9604 - loss: 0.2558 - val_auc: 0.9157 - val_loss: 0.3789\n",
      "Epoch 16/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - auc: 0.9576 - loss: 0.2646 - val_auc: 0.9154 - val_loss: 0.3762\n",
      "Epoch 17/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - auc: 0.9584 - loss: 0.2632 - val_auc: 0.9152 - val_loss: 0.3768\n",
      "Epoch 18/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - auc: 0.9532 - loss: 0.2773 - val_auc: 0.9152 - val_loss: 0.3801\n",
      "Epoch 19/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - auc: 0.9542 - loss: 0.2747 - val_auc: 0.9152 - val_loss: 0.3827\n",
      "Epoch 20/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - auc: 0.9587 - loss: 0.2615 - val_auc: 0.9146 - val_loss: 0.3874\n",
      "Epoch 21/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - auc: 0.9565 - loss: 0.2667 - val_auc: 0.9130 - val_loss: 0.3845\n",
      "Epoch 22/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - auc: 0.9601 - loss: 0.2564 - val_auc: 0.9120 - val_loss: 0.3868\n",
      "Epoch 23/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - auc: 0.9574 - loss: 0.2650 - val_auc: 0.9121 - val_loss: 0.3861\n",
      "Epoch 24/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - auc: 0.9555 - loss: 0.2696 - val_auc: 0.9127 - val_loss: 0.3857\n",
      "Epoch 25/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - auc: 0.9609 - loss: 0.2545 - val_auc: 0.9117 - val_loss: 0.3862\n",
      "Epoch 26/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - auc: 0.9624 - loss: 0.2497 - val_auc: 0.9127 - val_loss: 0.3849\n",
      "Epoch 27/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - auc: 0.9628 - loss: 0.2486 - val_auc: 0.9124 - val_loss: 0.3898\n",
      "Epoch 28/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9606 - loss: 0.2550 - val_auc: 0.9100 - val_loss: 0.3922\n",
      "Epoch 29/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - auc: 0.9633 - loss: 0.2496 - val_auc: 0.9107 - val_loss: 0.3960\n",
      "Epoch 30/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - auc: 0.9623 - loss: 0.2506 - val_auc: 0.9102 - val_loss: 0.3939\n",
      "Epoch 31/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - auc: 0.9604 - loss: 0.2565 - val_auc: 0.9120 - val_loss: 0.3940\n",
      "Epoch 32/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9593 - loss: 0.2597 - val_auc: 0.9109 - val_loss: 0.3976\n",
      "Epoch 33/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - auc: 0.9619 - loss: 0.2516 - val_auc: 0.9092 - val_loss: 0.4020\n",
      "Epoch 34/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - auc: 0.9628 - loss: 0.2485 - val_auc: 0.9091 - val_loss: 0.4005\n",
      "Epoch 35/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - auc: 0.9650 - loss: 0.2427 - val_auc: 0.9071 - val_loss: 0.3998\n",
      "Epoch 36/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - auc: 0.9645 - loss: 0.2443 - val_auc: 0.9070 - val_loss: 0.4047\n",
      "Epoch 37/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - auc: 0.9595 - loss: 0.2576 - val_auc: 0.9081 - val_loss: 0.4036\n",
      "Epoch 38/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - auc: 0.9649 - loss: 0.2410 - val_auc: 0.9086 - val_loss: 0.4072\n",
      "Epoch 39/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - auc: 0.9677 - loss: 0.2315 - val_auc: 0.9081 - val_loss: 0.4023\n",
      "Epoch 40/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - auc: 0.9671 - loss: 0.2334 - val_auc: 0.9100 - val_loss: 0.4096\n",
      "Epoch 41/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - auc: 0.9655 - loss: 0.2386 - val_auc: 0.9056 - val_loss: 0.4101\n",
      "Epoch 42/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - auc: 0.9652 - loss: 0.2401 - val_auc: 0.9086 - val_loss: 0.4061\n",
      "Epoch 43/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - auc: 0.9670 - loss: 0.2342 - val_auc: 0.9063 - val_loss: 0.4103\n",
      "Epoch 44/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - auc: 0.9664 - loss: 0.2358 - val_auc: 0.9064 - val_loss: 0.4077\n",
      "Epoch 45/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - auc: 0.9664 - loss: 0.2365 - val_auc: 0.9081 - val_loss: 0.4159\n",
      "Epoch 46/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - auc: 0.9675 - loss: 0.2324 - val_auc: 0.9060 - val_loss: 0.4133\n",
      "Epoch 47/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - auc: 0.9652 - loss: 0.2398 - val_auc: 0.9049 - val_loss: 0.4160\n",
      "Epoch 48/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - auc: 0.9675 - loss: 0.2326 - val_auc: 0.9042 - val_loss: 0.4166\n",
      "Epoch 49/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9703 - loss: 0.2233 - val_auc: 0.9049 - val_loss: 0.4221\n",
      "Epoch 50/50\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - auc: 0.9699 - loss: 0.2242 - val_auc: 0.9056 - val_loss: 0.4194\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - auc: 0.9117 - loss: 0.3960\n",
      "Test Loss, Test AUC: [0.39192718267440796, 0.9144033193588257]\n"
     ]
    }
   ],
   "source": [
    "#measuring performance with AUC\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss, Test AUC:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
